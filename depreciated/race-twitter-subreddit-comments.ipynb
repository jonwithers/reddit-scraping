{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying comments in r/BlackPeopleTwitter and r/WhitePeopleTwitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1,726,152 subscribers, BlackPeopleTwitter is one of the most popular subreddits on Reddit. In the words of the sub's description:  \n",
    "Screenshots of Black people being hilarious and insightful on social media, it doesn't need to just be twitter but obviously that is best.  \n",
    "Black culture has a unique way of examining the everyday and we are here to showcase that.  \n",
    "A community for three years.\n",
    "\n",
    "With 515,361 subscribers and also founded three years ago, WhitePeopleTwitter doesn't have a description but seems to be similar to BlackPeopleTwitter. The existence of two popular subreddits that are similar but organized around a different putative racial category is interesting.  \n",
    "\n",
    "The posts are screenshots from Twitter, and are either posted directly to Reddit in various image formats (e.g. .jpg) or are hosted on Imgur, an image hosting site. This means that we can't use natural language processing directly on the posts. Instead, we'll be looking at the comments. Do Reddit users use different enough language when responding to 'black' and 'white' Twitter posts that we can build a classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional problem: looking at comments means that we won't have data for posts that have no comments. It's fair to throw this data away since the question we've defined is about reactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "\n",
    "url_base = \"http://www.reddit.com/\"\n",
    "\n",
    "slug_hot = \"hot.json\"\n",
    "\n",
    "slug_bpt = \"r/BlackPeopleTwitter/\" # an optional intermediate slug to throw in to view a specific subreddit's 'hot' page\n",
    "slug_wpt = \"r/WhitePeopleTwitter/\"\n",
    "\n",
    "user = {'User-agent': 'JonBot 0.1'} # I need a User-agent to get in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Starting with BlackPeopleTwitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_bpt = url_base + slug_bpt + slug_hot\n",
    "res = requests.get(url_bpt, headers = user)\n",
    "data = res.json()\n",
    "i = 0 # this is the post number on this page\n",
    "slug_bpt_id = data['data']['children'][i]['data']['id']\n",
    "comments_this_post = data['data']['children'][i]['data']['num_comments'] # this is a requirement for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_bpt_comments = url_base + slug_bpt + 'comments/' + slug_bpt_id + '.json'\n",
    "\n",
    "res = requests.get(url_bpt_comments, headers = user)\n",
    "\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.reddit.com/r/BlackPeopleTwitter/comments/8mcaq9.json'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_bpt_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'after': None,\n",
       "  'before': None,\n",
       "  'children': [{'data': {'approved_at_utc': None,\n",
       "     'approved_by': None,\n",
       "     'archived': False,\n",
       "     'author': 'Nathan561',\n",
       "     'author_flair_css_class': 'mod',\n",
       "     'author_flair_template_id': None,\n",
       "     'author_flair_text': 'Mod',\n",
       "     'banned_at_utc': None,\n",
       "     'banned_by': None,\n",
       "     'can_gild': False,\n",
       "     'can_mod_post': False,\n",
       "     'clicked': False,\n",
       "     'contest_mode': False,\n",
       "     'created': 1527390320.0,\n",
       "     'created_utc': 1527361520.0,\n",
       "     'distinguished': 'moderator',\n",
       "     'domain': 'self.BlackPeopleTwitter',\n",
       "     'downs': 0,\n",
       "     'edited': False,\n",
       "     'gilded': 0,\n",
       "     'hidden': False,\n",
       "     'hide_score': False,\n",
       "     'id': '8mcaq9',\n",
       "     'is_crosspostable': False,\n",
       "     'is_reddit_media_domain': False,\n",
       "     'is_self': True,\n",
       "     'is_video': False,\n",
       "     'likes': None,\n",
       "     'link_flair_css_class': None,\n",
       "     'link_flair_text': None,\n",
       "     'locked': False,\n",
       "     'media': None,\n",
       "     'media_embed': {},\n",
       "     'media_only': False,\n",
       "     'mod_note': None,\n",
       "     'mod_reason_by': None,\n",
       "     'mod_reason_title': None,\n",
       "     'mod_reports': [],\n",
       "     'name': 't3_8mcaq9',\n",
       "     'no_follow': False,\n",
       "     'num_comments': 138,\n",
       "     'num_crossposts': 0,\n",
       "     'num_reports': None,\n",
       "     'over_18': False,\n",
       "     'parent_whitelist_status': 'promo_all',\n",
       "     'permalink': '/r/BlackPeopleTwitter/comments/8mcaq9/rblackpeopletwitter_weekly_discussion_thread_may/',\n",
       "     'pinned': False,\n",
       "     'post_categories': None,\n",
       "     'pwls': 5,\n",
       "     'quarantine': False,\n",
       "     'removal_reason': None,\n",
       "     'report_reasons': None,\n",
       "     'saved': False,\n",
       "     'score': 50,\n",
       "     'secure_media': None,\n",
       "     'secure_media_embed': {},\n",
       "     'selftext': \"Hey /r/BlackPeopleTwitter, welcome to our weekly Saturday discussion thread. We're going to try and keep this regularly posted if this is something that you all enjoy. \\n\\nFeel free to use this thread to discuss whatever you want. You can discuss the state of the sub / meta post, shitpost, post non-twitter memes, or discuss whats going on in your life. Just keep in mind that we ask you stay friendly and civil. \\n\\n\\n\\n\",\n",
       "     'selftext_html': '&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hey &lt;a href=\"/r/BlackPeopleTwitter\"&gt;/r/BlackPeopleTwitter&lt;/a&gt;, welcome to our weekly Saturday discussion thread. We&amp;#39;re going to try and keep this regularly posted if this is something that you all enjoy. &lt;/p&gt;\\n\\n&lt;p&gt;Feel free to use this thread to discuss whatever you want. You can discuss the state of the sub / meta post, shitpost, post non-twitter memes, or discuss whats going on in your life. Just keep in mind that we ask you stay friendly and civil. &lt;/p&gt;\\n&lt;/div&gt;&lt;!-- SC_ON --&gt;',\n",
       "     'send_replies': False,\n",
       "     'spoiler': False,\n",
       "     'stickied': True,\n",
       "     'subreddit': 'BlackPeopleTwitter',\n",
       "     'subreddit_id': 't5_33x33',\n",
       "     'subreddit_name_prefixed': 'r/BlackPeopleTwitter',\n",
       "     'subreddit_subscribers': 1730819,\n",
       "     'subreddit_type': 'public',\n",
       "     'suggested_sort': 'new',\n",
       "     'thumbnail': 'self',\n",
       "     'thumbnail_height': None,\n",
       "     'thumbnail_width': None,\n",
       "     'title': '/r/BlackPeopleTwitter Weekly Discussion Thread - May 26, 2018',\n",
       "     'ups': 50,\n",
       "     'upvote_ratio': 0.81,\n",
       "     'url': 'https://www.reddit.com/r/BlackPeopleTwitter/comments/8mcaq9/rblackpeopletwitter_weekly_discussion_thread_may/',\n",
       "     'user_reports': [],\n",
       "     'view_count': None,\n",
       "     'visited': False,\n",
       "     'whitelist_status': 'promo_all',\n",
       "     'wls': 5},\n",
       "    'kind': 't3'}],\n",
       "  'dist': 1,\n",
       "  'modhash': ''},\n",
       " 'kind': 'Listing'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuck I thought it was Sophie Dee. That would have been the only way I could have forgiven drake. \n",
      "\n",
      "In other news I think I’m gonna delete this account and take a long ass break from Reddit. Maybe I’ll lurk. I really wish the site were just memes and sports, but the toxic shit is like a magnet to me and I can’t let it ruin me. \n",
      "graduating high school in 3 days and my average isn't enough for university. might have to stick around this shit hole for another year. how was your day?\n",
      "Men get enough perks.  Can't women just have something nice for themselves?\n",
      "Tobe Nwigwe is 🔥\n",
      "I'm trying to off my ugly ass self \n"
     ]
    }
   ],
   "source": [
    "for j in range(5):\n",
    "    print(data[1]['data']['children'][j]['data']['body']) # Here's how to cycle through the comments for one post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subreddit_id',\n",
       " 'approved_at_utc',\n",
       " 'ups',\n",
       " 'mod_reason_by',\n",
       " 'banned_by',\n",
       " 'removal_reason',\n",
       " 'link_id',\n",
       " 'author_flair_template_id',\n",
       " 'likes',\n",
       " 'no_follow',\n",
       " 'replies',\n",
       " 'user_reports',\n",
       " 'saved',\n",
       " 'id',\n",
       " 'banned_at_utc',\n",
       " 'mod_reason_title',\n",
       " 'gilded',\n",
       " 'archived',\n",
       " 'report_reasons',\n",
       " 'author',\n",
       " 'can_mod_post',\n",
       " 'send_replies',\n",
       " 'parent_id',\n",
       " 'score',\n",
       " 'approved_by',\n",
       " 'downs',\n",
       " 'body',\n",
       " 'edited',\n",
       " 'author_flair_css_class',\n",
       " 'collapsed',\n",
       " 'is_submitter',\n",
       " 'collapsed_reason',\n",
       " 'body_html',\n",
       " 'subreddit_type',\n",
       " 'can_gild',\n",
       " 'subreddit',\n",
       " 'name',\n",
       " 'score_hidden',\n",
       " 'permalink',\n",
       " 'num_reports',\n",
       " 'stickied',\n",
       " 'created',\n",
       " 'author_flair_text',\n",
       " 'created_utc',\n",
       " 'subreddit_name_prefixed',\n",
       " 'controversiality',\n",
       " 'depth',\n",
       " 'mod_reports',\n",
       " 'mod_note',\n",
       " 'distinguished']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data[1]['data']['children'][0]['data'].keys()) # Here's all the keys for each comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking through the keys, I'm going to select the features that are most likely to be useful. At minimum, I'm going to pull out `body`, `subreddit_name_prefixed`, `created_utc`, and `body`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_utc: 1527656802.0\n",
      "subreddit_name_prefixed: r/BlackPeopleTwitter\n",
      "body: Fuck I thought it was Sophie Dee. That would have been the only way I could have forgiven drake. \n",
      "\n",
      "In other news I think I’m gonna delete this account and take a long ass break from Reddit. Maybe I’ll lurk. I really wish the site were just memes and sports, but the toxic shit is like a magnet to me and I can’t let it ruin me. \n",
      "ups: 5\n"
     ]
    }
   ],
   "source": [
    "features = ['created_utc','subreddit_name_prefixed', 'body', 'ups']\n",
    "for feature in features:\n",
    "    print(feature + \":\", data[1]['data']['children'][0]['data'][feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to loop these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://www.reddit.com/r/BlackPeopleTwitter/hot.json?after=t3_8mwi64'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_bpt = url_base + slug_bpt + slug_hot + '?after=t3_8mwi64'\n",
    "url_bpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url_bpt, headers = user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data']['children'][0]['data']['selftext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t3_8n2a97\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>comments_this_post</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>post_title</th>\n",
       "      <th>subreddit_name_prefixed</th>\n",
       "      <th>ups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fuck I thought it was Sophie Dee. That would h...</td>\n",
       "      <td>138</td>\n",
       "      <td>1.527657e+09</td>\n",
       "      <td>/r/BlackPeopleTwitter Weekly Discussion Thread...</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>As a surprise to zero people, Pusha T is a lot...</td>\n",
       "      <td>590</td>\n",
       "      <td>1.527642e+09</td>\n",
       "      <td>Pusha-T Responds to Drake</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>1466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>That or \"I am hiding a child, but you're hidin...</td>\n",
       "      <td>68</td>\n",
       "      <td>1.527688e+09</td>\n",
       "      <td>King Push vs King Pushover</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>She should have talked about Mexicans. Nobody ...</td>\n",
       "      <td>1151</td>\n",
       "      <td>1.527651e+09</td>\n",
       "      <td>You can understand how she'd be confused</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I’ve never seen a single tweet blow up in a ce...</td>\n",
       "      <td>66</td>\n",
       "      <td>1.527688e+09</td>\n",
       "      <td>When the Ambien hits</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boi just got \\n#Lit Up</td>\n",
       "      <td>27</td>\n",
       "      <td>1.527686e+09</td>\n",
       "      <td>UR BABY MAMA STINK</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I didn't know he had kids</td>\n",
       "      <td>110</td>\n",
       "      <td>1.527646e+09</td>\n",
       "      <td>Only partly, son</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Meek Mill is in the studio right now, flipping...</td>\n",
       "      <td>93</td>\n",
       "      <td>1.527650e+09</td>\n",
       "      <td>Pulitzer T</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>1378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gonna start calling Push uncle and it’s gonna ...</td>\n",
       "      <td>11</td>\n",
       "      <td>1.527684e+09</td>\n",
       "      <td>Better that than not spending any time with hi...</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>That was one of the least rewarding shows I've...</td>\n",
       "      <td>25</td>\n",
       "      <td>1.527690e+09</td>\n",
       "      <td>A true life achievement</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>There were two types of VCRs, ones where you w...</td>\n",
       "      <td>2715</td>\n",
       "      <td>1.527633e+09</td>\n",
       "      <td>Ain't that the truth!</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>5176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Pusha T is reacting like my girl after I jokin...</td>\n",
       "      <td>128</td>\n",
       "      <td>1.527644e+09</td>\n",
       "      <td>Drake should’ve kept quiet 😭</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>1255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>That kid would have been running around in 50’...</td>\n",
       "      <td>71</td>\n",
       "      <td>1.527647e+09</td>\n",
       "      <td>Gotta call fifty for his two cents.</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Did she fuck Trevor Noah?</td>\n",
       "      <td>1238</td>\n",
       "      <td>1.527628e+09</td>\n",
       "      <td>2018 really is nuts</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>6363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>This shit escalated quickly.</td>\n",
       "      <td>56</td>\n",
       "      <td>1.527647e+09</td>\n",
       "      <td>You got ish too</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&amp;gt;\\tWe got Roseanne cancelled.\\n\\nNah she go...</td>\n",
       "      <td>205</td>\n",
       "      <td>1.527639e+09</td>\n",
       "      <td>ALL OF THIS.</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>considering no one's really heard shit about t...</td>\n",
       "      <td>47</td>\n",
       "      <td>1.527647e+09</td>\n",
       "      <td>It be like that</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Yo that shit was cold tho</td>\n",
       "      <td>72</td>\n",
       "      <td>1.527645e+09</td>\n",
       "      <td>“I was just playing 😢”</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fuck it, you can take my child home with you!</td>\n",
       "      <td>26</td>\n",
       "      <td>1.527657e+09</td>\n",
       "      <td>Pusha L towards Drake</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Obama’s legacy will never be tarnished where a...</td>\n",
       "      <td>116</td>\n",
       "      <td>1.527631e+09</td>\n",
       "      <td>Anyone surprised?</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Dear pusha...im upset.</td>\n",
       "      <td>22</td>\n",
       "      <td>1.527654e+09</td>\n",
       "      <td>Drake in the studio</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>He only loves his bed and his mama</td>\n",
       "      <td>30</td>\n",
       "      <td>1.527661e+09</td>\n",
       "      <td>All jokes aside.</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I've read so much manga I tried to read right ...</td>\n",
       "      <td>21</td>\n",
       "      <td>1.527647e+09</td>\n",
       "      <td>Someone pass me my inhaler</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Fuck with your soul like ether</td>\n",
       "      <td>7</td>\n",
       "      <td>1.527662e+09</td>\n",
       "      <td>How do you respond? Woop Scoop Poop Di Scoop</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>OVO owl on the chest tho! 😂🤣😂 the Internet got...</td>\n",
       "      <td>13</td>\n",
       "      <td>1.527655e+09</td>\n",
       "      <td>While I'm at it I'd also like to report my own...</td>\n",
       "      <td>r/BlackPeopleTwitter</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 body  comments_this_post  \\\n",
       "0   Fuck I thought it was Sophie Dee. That would h...                 138   \n",
       "1   As a surprise to zero people, Pusha T is a lot...                 590   \n",
       "2   That or \"I am hiding a child, but you're hidin...                  68   \n",
       "3   She should have talked about Mexicans. Nobody ...                1151   \n",
       "4   I’ve never seen a single tweet blow up in a ce...                  66   \n",
       "5                              Boi just got \\n#Lit Up                  27   \n",
       "6                          I didn't know he had kids                  110   \n",
       "7   Meek Mill is in the studio right now, flipping...                  93   \n",
       "8   Gonna start calling Push uncle and it’s gonna ...                  11   \n",
       "9   That was one of the least rewarding shows I've...                  25   \n",
       "10  There were two types of VCRs, ones where you w...                2715   \n",
       "11  Pusha T is reacting like my girl after I jokin...                 128   \n",
       "12  That kid would have been running around in 50’...                  71   \n",
       "13                          Did she fuck Trevor Noah?                1238   \n",
       "14                       This shit escalated quickly.                  56   \n",
       "15  &gt;\\tWe got Roseanne cancelled.\\n\\nNah she go...                 205   \n",
       "16  considering no one's really heard shit about t...                  47   \n",
       "17                          Yo that shit was cold tho                  72   \n",
       "18      Fuck it, you can take my child home with you!                  26   \n",
       "19  Obama’s legacy will never be tarnished where a...                 116   \n",
       "20                             Dear pusha...im upset.                  22   \n",
       "21                He only loves his bed and his mama                   30   \n",
       "22  I've read so much manga I tried to read right ...                  21   \n",
       "23                    Fuck with your soul like ether                    7   \n",
       "24  OVO owl on the chest tho! 😂🤣😂 the Internet got...                  13   \n",
       "\n",
       "     created_utc                                         post_title  \\\n",
       "0   1.527657e+09  /r/BlackPeopleTwitter Weekly Discussion Thread...   \n",
       "1   1.527642e+09                          Pusha-T Responds to Drake   \n",
       "2   1.527688e+09                         King Push vs King Pushover   \n",
       "3   1.527651e+09           You can understand how she'd be confused   \n",
       "4   1.527688e+09                               When the Ambien hits   \n",
       "5   1.527686e+09                                 UR BABY MAMA STINK   \n",
       "6   1.527646e+09                                   Only partly, son   \n",
       "7   1.527650e+09                                         Pulitzer T   \n",
       "8   1.527684e+09  Better that than not spending any time with hi...   \n",
       "9   1.527690e+09                            A true life achievement   \n",
       "10  1.527633e+09                              Ain't that the truth!   \n",
       "11  1.527644e+09                       Drake should’ve kept quiet 😭   \n",
       "12  1.527647e+09                Gotta call fifty for his two cents.   \n",
       "13  1.527628e+09                                2018 really is nuts   \n",
       "14  1.527647e+09                                    You got ish too   \n",
       "15  1.527639e+09                                       ALL OF THIS.   \n",
       "16  1.527647e+09                                    It be like that   \n",
       "17  1.527645e+09                             “I was just playing 😢”   \n",
       "18  1.527657e+09                              Pusha L towards Drake   \n",
       "19  1.527631e+09                                  Anyone surprised?   \n",
       "20  1.527654e+09                                Drake in the studio   \n",
       "21  1.527661e+09                                   All jokes aside.   \n",
       "22  1.527647e+09                         Someone pass me my inhaler   \n",
       "23  1.527662e+09       How do you respond? Woop Scoop Poop Di Scoop   \n",
       "24  1.527655e+09  While I'm at it I'd also like to report my own...   \n",
       "\n",
       "   subreddit_name_prefixed   ups  \n",
       "0     r/BlackPeopleTwitter     4  \n",
       "1     r/BlackPeopleTwitter  1466  \n",
       "2     r/BlackPeopleTwitter   421  \n",
       "3     r/BlackPeopleTwitter  3269  \n",
       "4     r/BlackPeopleTwitter    56  \n",
       "5     r/BlackPeopleTwitter   137  \n",
       "6     r/BlackPeopleTwitter   605  \n",
       "7     r/BlackPeopleTwitter  1378  \n",
       "8     r/BlackPeopleTwitter    56  \n",
       "9     r/BlackPeopleTwitter    79  \n",
       "10    r/BlackPeopleTwitter  5176  \n",
       "11    r/BlackPeopleTwitter  1255  \n",
       "12    r/BlackPeopleTwitter   512  \n",
       "13    r/BlackPeopleTwitter  6363  \n",
       "14    r/BlackPeopleTwitter   349  \n",
       "15    r/BlackPeopleTwitter  1013  \n",
       "16    r/BlackPeopleTwitter   313  \n",
       "17    r/BlackPeopleTwitter   353  \n",
       "18    r/BlackPeopleTwitter   170  \n",
       "19    r/BlackPeopleTwitter   377  \n",
       "20    r/BlackPeopleTwitter   232  \n",
       "21    r/BlackPeopleTwitter    91  \n",
       "22    r/BlackPeopleTwitter   199  \n",
       "23    r/BlackPeopleTwitter    73  \n",
       "24    r/BlackPeopleTwitter    92  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "list_of_dictionaries = []\n",
    "for i in range(25):\n",
    "    \n",
    "# Setting up the top \n",
    "    this_dict = {}\n",
    "    url_bpt = url_base + slug_bpt + slug_hot\n",
    "    res = requests.get(url_bpt, headers = user)\n",
    "    data = res.json()\n",
    "    \n",
    "    slug_bpt_id = data['data']['children'][i]['data']['id']\n",
    "    comments_this_post = data['data']['children'][i]['data']['num_comments']\n",
    "    post_title = data['data']['children'][i]['data']['title']\n",
    "    \n",
    "    if (i+1)%25==0:\n",
    "        print(data['data']['after'])\n",
    "    \n",
    "    this_dict['comments_this_post'] = comments_this_post\n",
    "    this_dict['post_title'] = post_title\n",
    "    \n",
    "    url_bpt_comments = url_base + slug_bpt + 'comments/' + slug_bpt_id + '.json'\n",
    "    res = requests.get(url_bpt_comments, headers = user)\n",
    "    data = res.json()\n",
    "    features = ['created_utc','subreddit_name_prefixed', 'body', 'ups']\n",
    "    for feature in features:\n",
    "        this_dict[feature] = data[1]['data']['children'][0]['data'][feature]\n",
    "    time.sleep(1.1)\n",
    "    list_of_dictionaries.append(this_dict)\n",
    "\n",
    "pd.DataFrame(list_of_dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# list_of_dictionaries = []\n",
    "# aft = ''\n",
    "# features = ['created_utc', 'body', 'ups']\n",
    "# for i in range(100):\n",
    "#     j = i % 25\n",
    "#     this_dict = {}\n",
    "#     url_bpt = url_base + slug_bpt + slug_hot + aft\n",
    "#     res = requests.get(url_bpt, headers = user)\n",
    "#     data = res.json()\n",
    "    \n",
    "#     slug_bpt_id = data['data']['children'][j]['data']['id']\n",
    "#     comments_this_post = data['data']['children'][j]['data']['num_comments']\n",
    "#     post_title = data['data']['children'][j]['data']['title']\n",
    "    \n",
    "#     if (i+1)%25==0:\n",
    "#         print(data['data']['after'])\n",
    "#         aft = '?after='+data['data']['after']\n",
    "    \n",
    "#     this_dict['comments_this_post'] = comments_this_post\n",
    "#     this_dict['post_title'] = post_title\n",
    "# #     print(post_title)\n",
    "#     url_bpt_comments = url_base + slug_bpt + 'comments/' + slug_bpt_id + '.json'\n",
    "#     res = requests.get(url_bpt_comments, headers = user)\n",
    "#     data = res.json()\n",
    "#     try:\n",
    "#         comment_data = data[1]['data']['children'][0]['data']\n",
    "#     except:\n",
    "#         pass\n",
    "#     for feature in features:\n",
    "#         this_dict[feature] = comment_data[feature]\n",
    "# #     print(comment_data['ups'])\n",
    "#     time.sleep(1.1)\n",
    "#     list_of_dictionaries.append(this_dict)\n",
    "\n",
    "# pd.DataFrame(list_of_dictionaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_bpt100 = pd.DataFrame(list_of_dictionaries)\n",
    "# df_bpt100['sub'] = 0\n",
    "\n",
    "# df_bpt100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 posts scraped!\n",
      "50 posts scraped!\n",
      "75 posts scraped!\n",
      "100 posts scraped!\n",
      "125 posts scraped!\n",
      "150 posts scraped!\n",
      "175 posts scraped!\n",
      "200 posts scraped!\n",
      "225 posts scraped!\n",
      "250 posts scraped!\n",
      "275 posts scraped!\n",
      "300 posts scraped!\n",
      "325 posts scraped!\n",
      "350 posts scraped!\n",
      "375 posts scraped!\n",
      "400 posts scraped!\n",
      "425 posts scraped!\n",
      "450 posts scraped!\n",
      "475 posts scraped!\n",
      "500 posts scraped!\n",
      "525 posts scraped!\n",
      "550 posts scraped!\n",
      "575 posts scraped!\n",
      "600 posts scraped!\n",
      "625 posts scraped!\n",
      "650 posts scraped!\n",
      "675 posts scraped!\n",
      "700 posts scraped!\n",
      "725 posts scraped!\n",
      "750 posts scraped!\n",
      "775 posts scraped!\n",
      "800 posts scraped!\n",
      "825 posts scraped!\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9653bf1620ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mslug_bpt_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mcomments_this_post\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_comments'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpost_title\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'children'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "list_of_dictionaries = []\n",
    "aft = ''\n",
    "features = ['created_utc', 'body', 'ups']\n",
    "\n",
    "for i in range(2000):\n",
    "    j = i % 25\n",
    "    this_dict = {}\n",
    "    url_bpt = url_base + slug_bpt + slug_hot + aft\n",
    "    res = requests.get(url_bpt, headers = user)\n",
    "    data = res.json()\n",
    "\n",
    "    slug_bpt_id = data['data']['children'][j]['data']['id']\n",
    "    comments_this_post = data['data']['children'][j]['data']['num_comments']\n",
    "    post_title = data['data']['children'][j]['data']['title']\n",
    "    \n",
    "    if (i+1)%25==0:\n",
    "        print(\"{} posts scraped!\".format(i+1))\n",
    "        aft = '?after='+data['data']['after']\n",
    "    \n",
    "    this_dict['comments_this_post'] = comments_this_post\n",
    "    this_dict['post_title'] = post_title\n",
    "#     print(post_title)\n",
    "    url_bpt_comments = url_base + slug_bpt + 'comments/' + slug_bpt_id + '.json'\n",
    "    res = requests.get(url_bpt_comments, headers = user)\n",
    "    data = res.json()\n",
    "    try:\n",
    "        comment_data = data[1]['data']['children'][0]['data']\n",
    "    except:\n",
    "        pass\n",
    "    for feature in features:\n",
    "        this_dict[feature] = comment_data[feature]\n",
    "#     print(comment_data['ups'])\n",
    "    time.sleep(3)\n",
    "    list_of_dictionaries.append(this_dict)\n",
    "\n",
    "pd.DataFrame(list_of_dictionaries).to_csv('Bpt_2000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list_of_dictionaries).to_csv(\"bpt_scraped_109pm_may30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "slug_wpt = 'r/WhitePeopleTwitter/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hot.json'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slug_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 posts scraped!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e2ad31bae3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mthis_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomment_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m#     print(comment_data['ups'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mlist_of_dictionaries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_of_dictionaries = []\n",
    "aft = ''\n",
    "features = ['created_utc', 'body', 'ups']\n",
    "\n",
    "for i in range(1000):\n",
    "    j = i % 25\n",
    "    this_dict = {}\n",
    "    url_wpt = url_base + slug_wpt + slug_hot + aft\n",
    "    res = requests.get(url_wpt, headers = user)\n",
    "    data = res.json()\n",
    "\n",
    "    slug_wpt_id = data['data']['children'][j]['data']['id']\n",
    "    comments_this_post = data['data']['children'][j]['data']['num_comments']\n",
    "    post_title = data['data']['children'][j]['data']['title']\n",
    "    \n",
    "    if (i+1)%25==0:\n",
    "        print(\"{} posts scraped!\".format(i+1))\n",
    "        aft = '?after='+data['data']['after']\n",
    "    \n",
    "    this_dict['comments_this_post'] = comments_this_post\n",
    "    this_dict['post_title'] = post_title\n",
    "#     print(post_title)\n",
    "    url_wpt_comments = url_base + slug_wpt + 'comments/' + slug_wpt_id + '.json'\n",
    "    res = requests.get(url_wpt_comments, headers = user)\n",
    "    data = res.json()\n",
    "    try:\n",
    "        comment_data = data[1]['data']['children'][0]['data']\n",
    "    except:\n",
    "        pass\n",
    "    for feature in features:\n",
    "        this_dict[feature] = comment_data[feature]\n",
    "#     print(comment_data['ups'])\n",
    "    time.sleep(3)\n",
    "    list_of_dictionaries.append(this_dict)\n",
    "\n",
    "pd.DataFrame(list_of_dictionaries).to_csv('Wpt_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1527700578.5692391 for the bpt twitter thing from may 30.\n",
    "\n",
    "# 1527704638.661053 for the wpt twitter thing from may 30.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_of_dictionaries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3d9cda2cd220>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlist_of_dictionaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'list_of_dictionaries' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "list_of_dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
